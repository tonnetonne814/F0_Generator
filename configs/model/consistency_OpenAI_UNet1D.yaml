_target_: source.model_module.consistency_wavenet_module.ConsistencyWaveNetModule

optimizer_g:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 1e-4
  betas: [0.9, 0.995]
  eps : 1e-9

scheduler_g:
  _target_: torch.optim.lr_scheduler.ExponentialLR
  _partial_: true
  gamma: 0.999999 #875 # lr_decay

net_g:
  _target_: source.model_module.models.consistency_OpenAI_Unet1D.ConsistencyModels
  hps:
    f0:
      max : 1100
      min : 65
      normalize : "[-1,1]" #log_scale, [0,1], [-1,1]
    Consistency:
      use_improved_consistency : True # True # improved
      initial_ema_decay_rate: 0.95
      student_model_ema_decay_rate : 0.999993
      sigma_min: 0.002
      sigma_max: 80.0
      rho: 7.0
      sigma_data: 0.5
      initial_timesteps: 10 # improved # normal 2
      final_timesteps: 1280 # improved # normal 150
      # improved only
      lognormal_mean : -1.1
      lognormal_std : 2.0
      # sampling
      num_samples : 8
      start_from_y : False
      add_initial_noise : True
      clip_denoised : false
      verbose : False
      sampling_sigmas : [
                          [80],
                          [80.0, 0.661],
                          [80.0, 24.4, 5.84, 0.9, 0.661]
                        ]
    NoisePredictor:
      vocab_size : 256
      out_channels : 1
      inner_channels : 192
      WN_in_channels : 1          # 固定で
      WN_kernel_size : 5          # 固定で
      WN_dilation_rate : 1        # 固定で
      WN_n_layers : 16            # 固定で
      WN_p_dropout : 0            # 固定で
      Attn_filter_channels : 256
      Attn_n_layers : 6
      Attn_n_heads : 2
      Attn_kernel_size : 3
      Attn_p_dropout : 0.1
      Diff_step_embed_in : 128
      #Diff_step_embed_mid : 512
      #Diff_step_embed_out : 512
      n_speakers : 1
      gin_channels : 192
    NoteEncoder :
      n_note : 127
      hidden_channels : 192
    OpenAI_UnetConfig:
      in_channels: 384
      model_channels: 192
      out_channels: 1
      num_res_blocks: 2
      attention_resolutions: [32,16,8,4]
      dropout: 0
      channel_mult: [1, 2, 4, 8]
      conv_resample: True
      dims: 1
      num_classes: null
      use_checkpoint: False
      use_fp16: False
      num_heads: 4
      num_head_channels: -1
      num_heads_upsample: -1
      use_scale_shift_norm: False
      resblock_updown: False
      use_new_attention_order: False
# GAN等、ここで書いたら、moduleにも書き直す
# net_d:
#   _target_: source.model_module.models.ddpm_wavenet.DiffusionDiscriminator
#   hps:
#     f0:
#       max : 1100
#       min : 65

# compile model for faster training with pytorch 2.0
compile: false
valid_sampling_in_n_epoch : 10